<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>Hybrid OCR: Tesseract + PaddleOCR fallback → Chunked Translation</title>

<!-- Tesseract.js v5 -->
<script src="https://cdn.jsdelivr.net/npm/tesseract.js@5/dist/tesseract.min.js"></script>

<style>
  :root{ --bg:#071021; --card:#0f1720; --muted:#9fb0c8; --accent1:#ff6b81; --accent2:#8a2be2; --text:#e6eef7; }
  body{ margin:0; font-family:Inter,Arial,Helvetica,sans-serif; background:linear-gradient(180deg,#03040a,#071021); color:var(--text); }
  .wrap{max-width:980px;margin:20px auto;padding:18px;border-radius:12px;background:rgba(255,255,255,0.02);border:1px solid rgba(255,255,255,0.03)}
  h1{margin:0;font-size:20px}
  .lead{color:var(--muted);font-size:13px;margin-top:6px}
  .grid{display:flex;gap:12px;margin-top:12px;flex-wrap:wrap}
  .col{flex:1;min-width:280px}
  .card{padding:12px;border-radius:10px;background:var(--card);border:1px solid rgba(255,255,255,0.02)}
  input[type=file]{width:100%}
  .preview{width:100%;max-height:320px;object-fit:contain;border-radius:8px;background:#fff;margin-top:8px;display:none}
  .box{width:100%;min-height:140px;border-radius:8px;padding:10px;background:#071018;color:var(--text);font-family:monospace;white-space:pre-wrap;overflow:auto}
  .controls{display:flex;gap:8px;flex-wrap:wrap;margin-top:8px}
  button{padding:10px 12px;border-radius:10px;border:0;background:linear-gradient(90deg,var(--accent1),var(--accent2));color:white;cursor:pointer}
  .secondary{background:transparent;border:1px solid rgba(255,255,255,0.06);color:var(--text)}
  .small{font-size:13px;color:var(--muted)}
  .log{max-height:240px;overflow:auto;padding:10px;background:rgba(0,0,0,0.25);border-radius:8px;font-family:monospace;font-size:13px}
  .credits{font-family:Pacifico,cursive;text-align:right;margin-top:10px;color:rgba(255,255,255,0.9)}
  label.input-row{display:block;margin-top:10px;font-size:13px}
  input.text{width:100%;padding:8px;border-radius:6px;border:1px solid rgba(255,255,255,0.04);background:transparent;color:var(--text)}
  .hint{font-size:12px;color:var(--muted);margin-top:6px}
  @media(max-width:820px){ .grid{flex-direction:column} .col{min-width:unset} }
</style>
</head>
<body>
  <div class="wrap">
    <div style="display:flex;justify-content:space-between;align-items:center">
      <div>
        <h1>Hybrid OCR — Tesseract + PaddleOCR fallback → English Translation</h1>
        <div class="lead">Preprocess → Tesseract (kan then eng) → PaddleOCR (optional) → chunked translation with fallbacks</div>
      </div>
    </div>

    <div class="grid" style="margin-top:12px">
      <div class="col card">
        <div class="small">Upload image (photo / screenshot). Processing starts automatically.</div>
        <input id="fileInput" type="file" accept="image/*" style="margin-top:8px"/>
        <div style="margin-top:10px" class="controls">
          <button id="processNow" class="secondary">Process Now</button>
          <button id="retryBtn" class="secondary">Retry last</button>
        </div>

        <img id="preview" class="preview" alt="preview"/>

        <label class="input-row small">PaddleOCR server endpoint (optional; POST image data URL or multipart):</label>
        <input id="paddleEndpoint" class="text" placeholder="https://your-paddle-ocr-server/ocr" />

        <div class="hint">Tip: For best OCR, use well-lit, flat images. Turtle-neck or shadowed text reduces accuracy.</div>

        <div style="margin-top:10px" class="small">Pipeline Log</div>
        <div id="log" class="log">Idle. Upload an image to start.</div>
      </div>

      <div class="col card">
        <div class="small">OCR Combined Output (Kannada first + English)</div>
        <div id="ocrBox" class="box">(OCR will appear here)</div>
        <div class="controls">
          <button id="downloadOcr" class="secondary">Download OCR</button>
          <button id="copyOcr" class="secondary">Copy OCR</button>
        </div>

        <div style="margin-top:12px" class="small">English Translation (chunked & fallback)</div>
        <div id="transBox" class="box">(Translation will appear here)</div>
        <div class="controls" style="margin-top:8px">
          <button id="downloadTrans" class="secondary">Download Translation</button>
          <button id="retryTrans" class="secondary">Retry Translation</button>
        </div>

        <div class="credits">Created by Animesh</div>
      </div>
    </div>
  </div>

<script>
/* =========================
   CONFIG
   ========================= */
const ROTATIONS = [-5,-3,-2,-1,0,1,2,3,5];  // rotations to try
const MAX_DIM = 1800;        // max resize (upscale small images for better OCR)
const CHUNK_SIZE = 420;      // translation chunk size
const OCR_TIMEOUT = 30000;   // ms per recognition
const TRANSLATION_TIMEOUT = 12000;
const MIN_KANNADA_CONF = 15;

/* translators fallback list */
const TRANSLATORS = [
  { name:'MyMemory', type:'get', build: t => `https://api.mymemory.translated.net/get?q=${encodeURIComponent(t)}&langpair=kn|en` },
  { name:'libretranslate.de', type:'post', url:'https://libretranslate.de/translate' },
  { name:'argosopentech', type:'post', url:'https://translate.argosopentech.com/translate' },
  { name:'astian', type:'post', url:'https://translate.astian.org/translate' }
];

/* ============= DOM ============= */
const fileInput = document.getElementById('fileInput');
const processNow = document.getElementById('processNow');
const retryBtn = document.getElementById('retryBtn');
const preview = document.getElementById('preview');
const paddleEndpointEl = document.getElementById('paddleEndpoint');
const logEl = document.getElementById('log');
const ocrBox = document.getElementById('ocrBox');
const transBox = document.getElementById('transBox');
const downloadOcr = document.getElementById('downloadOcr');
const copyOcr = document.getElementById('copyOcr');
const downloadTrans = document.getElementById('downloadTrans');
const retryTrans = document.getElementById('retryTrans');

let lastFile = null, lastCombinedText = '', lastTranslation = '';

/* ============= helpers ============= */
function log(msg){
  const ts = new Date().toLocaleTimeString();
  logEl.textContent = `${ts} — ${msg}\n` + logEl.textContent;
  console.log(msg);
}
function showOcr(t){ ocrBox.textContent = t || '(no OCR)'; }
function showTrans(t){ transBox.textContent = t || '(no translation)'; }
function downloadText(filename, text){ const a=document.createElement('a'); a.href=URL.createObjectURL(new Blob([text||''],{type:'text/plain'})); a.download=filename; a.click(); }
function copyText(t){ navigator.clipboard?.writeText(t).then(()=>alert('Copied'), ()=>alert('Copy failed')); }

/* ================= Image preprocessing utilities ================= */

function resizeCanvas(img, maxDim=MAX_DIM){
  // upscale small images up to 2x for better OCR
  const scale = Math.min(2, Math.max(1, maxDim / Math.max(img.width, img.height)));
  const c = document.createElement('canvas');
  c.width = Math.round(img.width * scale);
  c.height = Math.round(img.height * scale);
  const ctx = c.getContext('2d');
  ctx.imageSmoothingEnabled = true;
  ctx.imageSmoothingQuality = 'high';
  ctx.drawImage(img, 0, 0, c.width, c.height);
  return c;
}

function toGrayscale(c){
  const ctx = c.getContext('2d');
  const id = ctx.getImageData(0,0,c.width,c.height);
  const d = id.data;
  for (let i=0;i<d.length;i+=4){
    const v = Math.round(0.299*d[i] + 0.587*d[i+1] + 0.114*d[i+2]);
    d[i]=d[i+1]=d[i+2]=v;
  }
  ctx.putImageData(id,0,0);
  return c;
}

function contrastBoost(c, factor=1.5){
  try {
    const ctx = c.getContext('2d');
    const id = ctx.getImageData(0,0,c.width,c.height);
    const d = id.data;
    for (let i=0;i<d.length;i+=4){
      for (let k=0;k<3;k++){
        let v = d[i+k];
        v = ((v - 128) * factor) + 128;
        d[i+k] = Math.max(0, Math.min(255, Math.round(v)));
      }
    }
    ctx.putImageData(id,0,0);
  } catch(e){ log('contrastBoost err:'+e.message); }
  return c;
}

function applyCanvasFilter(c, filter){
  try {
    const tmp = document.createElement('canvas');
    tmp.width = c.width; tmp.height = c.height;
    const tctx = tmp.getContext('2d');
    tctx.filter = filter;
    tctx.drawImage(c,0,0);
    return tmp;
  } catch(e){
    return c;
  }
}

function otsuThreshold(c){
  try {
    const ctx = c.getContext('2d');
    const w = c.width, h = c.height;
    const id = ctx.getImageData(0,0,w,h);
    const d = id.data;
    const hist = new Array(256).fill(0);
    for (let i=0;i<d.length;i+=4) hist[d[i]]++;
    const total = w*h;
    let sum=0;
    for (let t=0;t<256;t++) sum += t*hist[t];
    let sumB=0, wB=0, varMax=0, threshold=0;
    for (let t=0;t<256;t++){
      wB += hist[t];
      if (wB === 0) continue;
      const wF = total - wB;
      if (wF === 0) break;
      sumB += t*hist[t];
      const mB = sumB/wB;
      const mF = (sum - sumB)/wF;
      const varBetween = wB * wF * (mB - mF) * (mB - mF);
      if (varBetween > varMax){ varMax = varBetween; threshold = t; }
    }
    for (let i=0;i<d.length;i+=4){
      const v = d[i] > threshold ? 255 : 0;
      d[i]=d[i+1]=d[i+2]=v;
    }
    ctx.putImageData(id,0,0);
  } catch(e){ log('otsu err:'+e.message); }
  return c;
}

function morphologicalOpen(c, iterations=1){
  // simple open (erode then dilate) on binary image
  try {
    const w=c.width, h=c.height;
    const ctx = c.getContext('2d');
    const id = ctx.getImageData(0,0,w,h);
    const d = id.data;
    const src = new Uint8Array(w*h);
    for (let i=0,j=0;i<d.length;i+=4,j++) src[j] = d[i] > 128 ? 1 : 0;
    // erosion
    for (let it=0; it<iterations; it++){
      const tmp = src.slice();
      for (let y=1;y<h-1;y++){
        for (let x=1;x<w-1;x++){
          let anyZero=false;
          for (let yy=-1; yy<=1; yy++){
            for (let xx=-1; xx<=1; xx++){
              if (src[(y+yy)*w + (x+xx)] === 0){ anyZero=true; break; }
            }
            if (anyZero) break;
          }
          tmp[y*w+x] = anyZero ? 0 : 1;
        }
      }
      src.set(tmp);
    }
    // dilation
    for (let it=0; it<iterations; it++){
      const tmp = src.slice();
      for (let y=1;y<h-1;y++){
        for (let x=1;x<w-1;x++){
          if (src[y*w+x] === 1){
            for (let yy=-1; yy<=1; yy++){
              for (let xx=-1; xx<=1; xx++){
                tmp[(y+yy)*w + (x+xx)] = 1;
              }
            }
          }
        }
      }
      src.set(tmp);
    }
    for (let j=0,i=0;j<src.length;j++,i+=4){
      const v = src[j] ? 255 : 0;
      d[i]=d[i+1]=d[i+2]=v;
    }
    ctx.putImageData(id,0,0);
  } catch(e){ log('morph err:'+e.message); }
  return c;
}

function rotateCanvas(src, deg){
  const r = deg * Math.PI/180;
  const w = src.width, h = src.height;
  const sin = Math.abs(Math.sin(r)), cos = Math.abs(Math.cos(r));
  const nw = Math.ceil(w*cos + h*sin), nh = Math.ceil(w*sin + h*cos);
  const c = document.createElement('canvas'); c.width = nw; c.height = nh;
  const ctx = c.getContext('2d');
  ctx.fillStyle = 'white'; ctx.fillRect(0,0,nw,nh);
  ctx.translate(nw/2, nh/2); ctx.rotate(r); ctx.drawImage(src, -w/2, -h/2);
  return c;
}
function canvasToDataUrl(c){ return c.toDataURL('image/png'); }

/* ========= Tesseract wrapper ========= */
function recognizeWithTimeout(dataUrl, lang='kan', timeout=OCR_TIMEOUT){
  return new Promise(async (resolve, reject) => {
    let timed=false;
    const timer = setTimeout(()=>{ timed=true; reject(new Error('OCR timeout')); }, timeout);
    try {
      // logger suppressed for cleaner UI; change if you want verbose logs
      const opts = {
        logger: m => { /* silent */ },
        tessedit_pageseg_mode: 6, // assume a block of text
        preserve_interword_spaces: 1
      };
      const res = await Tesseract.recognize(dataUrl, lang, opts);
      if (!timed){ clearTimeout(timer); resolve(res.data); }
    } catch(err){
      if (!timed){ clearTimeout(timer); reject(err); }
    }
  });
}

/* ========= PaddleOCR client (optional) ========= */
async function callPaddleOcrServer(dataUrl, endpoint){
  try {
    // first try JSON body with image dataUrl
    let res = await fetch(endpoint, {
      method:'POST',
      headers:{ 'Content-Type':'application/json' },
      body: JSON.stringify({ image: dataUrl })
    });
    if (!res.ok){
      // fallback multipart form
      const blob = await (await fetch(dataUrl)).blob();
      const form = new FormData();
      form.append('image', blob, 'image.png');
      res = await fetch(endpoint, { method:'POST', body: form });
    }
    if (!res.ok) throw new Error('HTTP '+res.status);
    const j = await res.json();
    if (j.text) return j.text;
    if (j.lines && Array.isArray(j.lines)) return j.lines.map(l=>l.text||l).join('\n');
    if (j.data && j.data.text) return j.data.text;
    return JSON.stringify(j);
  } catch(e){
    log('PaddleOCR call failed: '+e.message);
    return null;
  }
}

/* ========= translation helpers ========= */
function chunkText(text, maxLen=CHUNK_SIZE){
  const paragraphs = text.split(/\n{2,}/g);
  const chunks = [];
  for (const p of paragraphs){
    if (!p.trim()) continue;
    let remaining = p.trim();
    while (remaining.length > 0){
      if (remaining.length <= maxLen){ chunks.push(remaining); break; }
      const sub = remaining.slice(0, maxLen);
      let splitPos = Math.max(sub.lastIndexOf('.'), sub.lastIndexOf('।'), sub.lastIndexOf('?'), sub.lastIndexOf('!'), sub.lastIndexOf('\n'));
      if (splitPos > Math.floor(maxLen*0.6)){
        chunks.push(remaining.slice(0, splitPos+1).trim());
        remaining = remaining.slice(splitPos+1).trim();
      } else {
        const sp = sub.lastIndexOf(' ');
        const cut = (sp > 50) ? sp : maxLen;
        chunks.push(remaining.slice(0, cut).trim());
        remaining = remaining.slice(cut).trim();
      }
    }
  }
  if (chunks.length === 0 && text.trim()) chunks.push(text.trim().slice(0,maxLen));
  return chunks;
}

function fetchWithTimeout(url, opts={}, ms=8000){
  return new Promise((resolve,reject)=>{
    const timer = setTimeout(()=>reject(new Error('timeout')), ms);
    fetch(url, opts).then(res=>{ clearTimeout(timer); resolve(res); }).catch(err=>{ clearTimeout(timer); reject(err); });
  });
}

async function translateChunkWithEp(chunk, ep){
  try {
    if (ep.type === 'get'){
      const url = ep.build(chunk);
      const res = await fetchWithTimeout(url, {}, TRANSLATION_TIMEOUT);
      if (!res.ok) throw new Error('HTTP '+res.status);
      const j = await res.json();
      const t = j.responseData && j.responseData.translatedText;
      if (t) return { ok:true, text:t, source:ep.name };
      return { ok:false };
    } else {
      const res = await fetchWithTimeout(ep.url, {
        method:'POST',
        headers:{ 'Content-Type':'application/json' },
        body: JSON.stringify({ q: chunk, source:'kn', target:'en', format:'text' })
      }, TRANSLATION_TIMEOUT);
      if (!res.ok) throw new Error('HTTP '+res.status);
      const j = await res.json();
      const t = j.translatedText || j.translation || (j.data && j.data.translations && j.data.translations[0] && j.data.translations[0].translatedText) || null;
      if (t) return { ok:true, text:t, source:ep.name };
      return { ok:false };
    }
  } catch(e){
    log(`${ep.name} failed: ${e.message}`);
    return { ok:false };
  }
}

async function doTranslationChunks(fullText){
  try {
    showTrans('Translating…'); log('Preparing chunks for translation...');
    const chunks = chunkText(fullText, CHUNK_SIZE);
    log(`Chunks: ${chunks.length}`);
    const results = [];
    for (let i=0;i<chunks.length;i++){
      const chunk = chunks[i];
      log(`Translating chunk ${i+1}/${chunks.length} (len=${chunk.length})`);
      let translated = null;
      for (const ep of TRANSLATORS){
        const res = await translateChunkWithEp(chunk, ep);
        if (res.ok){ translated = res.text; log(`Chunk ${i+1} translated by ${res.source}`); break; }
      }
      if (!translated){ translated = '[Translation unavailable for this chunk]'; log(`Chunk ${i+1} failed on all endpoints.`); }
      results.push(translated);
      await new Promise(r=>setTimeout(r, 200));
    }
    const final = results.join('\n\n');
    lastTranslation = final;
    showTrans(final);
    log('Translation complete.');
  } catch(e){
    log('Translation pipeline error: '+(e && e.message));
    showTrans('Translation failed.');
  }
}

/* ========= Main pipeline ========= */

fileInput.addEventListener('change', e=>{
  const f = e.target.files && e.target.files[0];
  if (f){ lastFile = f; preview.src = URL.createObjectURL(f); preview.style.display='block'; runPipeline(f); }
});
processNow.addEventListener('click', ()=>{ if (fileInput.files[0]) runPipeline(fileInput.files[0]); else alert('Choose an image'); });
retryBtn.addEventListener('click', ()=>{ if (lastFile) runPipeline(lastFile); else alert('No last file'); });
retryTrans.addEventListener('click', ()=>{ if (lastCombinedText) doTranslationChunks(lastCombinedText); else alert('No OCR text'); });
downloadOcr.addEventListener('click', ()=> downloadText('ocr.txt', lastCombinedText));
copyOcr.addEventListener('click', ()=> copyText(lastCombinedText));
downloadTrans.addEventListener('click', ()=> downloadText('translation.txt', lastTranslation));

async function runPipeline(file){
  try {
    log('Starting pipeline for file: ' + file.name);
    showOcr('(processing...)'); showTrans('(waiting...)');

    const img = new Image();
    img.src = URL.createObjectURL(file);
    await img.decode();

    // 1) base resize/upscale
    const base = resizeCanvas(img, MAX_DIM);

    // build variants with different enhancements
    const variants = [];

    // plain: grayscale + slight contrast
    const plain = document.createElement('canvas'); plain.width = base.width; plain.height = base.height;
    plain.getContext('2d').drawImage(base,0,0);
    toGrayscale(plain); contrastBoost(plain,1.4);
    variants.push({name:'plain', canvas: plain});

    // blurred + contrast (reduces noise)
    const blur = applyCanvasFilter(plain, 'blur(1px) contrast(120%)');
    variants.push({name:'blur', canvas: blur});

    // otsu threshold + open
    const otsu = document.createElement('canvas'); otsu.width = base.width; otsu.height = base.height;
    otsu.getContext('2d').drawImage(base,0,0);
    toGrayscale(otsu); contrastBoost(otsu,1.3); otsuThreshold(otsu); morphologicalOpen(otsu,1);
    variants.push({name:'otsu', canvas: otsu});

    // extra sharpen
    const sharp = applyCanvasFilter(base, 'contrast(140%) brightness(105%)');
    variants.push({name:'sharp', canvas: sharp});

    // 2) Try Kannada-only OCR across variants & rotations (so Kannada glyphs are preserved)
    let bestKan = {score:-1, text:'', details:null};
    for (const v of variants){
      for (const rot of ROTATIONS){
        const canvas = (rot === 0) ? v.canvas : rotateCanvas(v.canvas, rot);
        const dataUrl = canvasToDataUrl(canvas);
        log(`KAN try: variant=${v.name}, rot=${rot}°`);
        try {
          const data = await recognizeWithTimeout(dataUrl, 'kan', OCR_TIMEOUT);
          const text = (data && data.text) ? data.text.trim() : '';
          const kcount = (text.match(/[\u0C80-\u0CFF]/g) || []).length;
          const score = kcount*5 + text.replace(/\s+/g,'').length;
          log(`KAN result len=${text.length}, kannada=${kcount}, score=${score}`);
          if (score > bestKan.score){ bestKan = {score, text, details:{variant:v.name,rot}}; showOcr(bestKan.text); }
          if (kcount >= Math.max(MIN_KANNADA_CONF, Math.floor((canvas.width*canvas.height) / 50000))){ log('KAN early accept'); break; }
        } catch(err){
          log(`KAN failed variant=${v.name}, rot=${rot}: ${err.message}`);
        }
      }
      if (bestKan.score > 4000) break;
    }

    // 3) English-only OCR on the best-looking plain/sharp variant
    let bestEng = {score:-1, text:'', details:null};
    const engCandidates = [variants.find(v=>v.name==='plain') || variants[0], variants.find(v=>v.name==='sharp') || variants[0]];
    for (const v of engCandidates){
      for (const rot of ROTATIONS){
        const canvas = (rot===0) ? v.canvas : rotateCanvas(v.canvas, rot);
        const dataUrl = canvasToDataUrl(canvas);
        log(`ENG try: variant=${v.name}, rot=${rot}°`);
        try {
          const data = await recognizeWithTimeout(dataUrl, 'eng', OCR_TIMEOUT);
          const text = (data && data.text) ? data.text.trim() : '';
          const score = text.replace(/\s+/g,'').length;
          log(`ENG result len=${text.length}, score=${score}`);
          if (score > bestEng.score){ bestEng = {score, text, details:{variant:v.name, rot}}; }
          if (score > 40) break;
        } catch(err){
          log(`ENG failed variant=${v.name}, rot=${rot}: ${err.message}`);
        }
      }
    }

    // combine: Kannada first (unaltered), then English-only segments extracted from bestEng
    const kanText = bestKan.text || '';
    let engText = bestEng.text || '';
    // remove any Kannada glyphs from english text
    engText = engText.replace(/[\u0C80-\u0CFF]+/g, '').trim();
    const combined = ((kanText + "\n\n" + engText).trim()).replace(/\r/g,'');
    lastCombinedText = combined;
    showOcr(combined || '(no OCR result)');
    log(`Selected KAN variant=${bestKan.details?.variant||'n/a'} rot=${bestKan.details?.rot||0} score=${bestKan.score}`);
    log(`Selected ENG variant=${bestEng.details?.variant||'n/a'} rot=${bestEng.details?.rot||0} score=${bestEng.score}`);

    // if combined looks poor, optionally call PaddleOCR endpoint (if provided)
    const kcountTotal = (combined.match(/[\u0C80-\u0CFF]/g) || []).length;
    const combinedLen = (combined || '').replace(/\s/g,'').length;
    const paddleEndpoint = (paddleEndpointEl.value || '').trim();

    if ((kcountTotal < MIN_KANNADA_CONF && combinedLen < 50) && paddleEndpoint){
      log('OCR quality low — trying PaddleOCR fallback');
      const baseUrl = canvasToDataUrl(base);
      const paddleText = await callPaddleOcrServer(baseUrl, paddleEndpoint);
      if (paddleText){
        log('PaddleOCR returned text — using it.');
        lastCombinedText = paddleText;
        showOcr(paddleText);
      } else {
        log('PaddleOCR fallback failed.');
      }
    } else if ((kcountTotal < MIN_KANNADA_CONF && combinedLen < 50) && !paddleEndpoint){
      log('OCR poor and no Paddle endpoint configured. Provide Paddle endpoint or retry with clearer image.');
      showTrans('No translation: OCR poor and no Paddle fallback.');
      return;
    }

    // final sanity
    if (!lastCombinedText || lastCombinedText.trim().length < 6){
      log('No useful OCR recovered. Try clearer photo (closer, flat, straight).');
      showTrans('No translation: no useful OCR text.');
      return;
    }

    // translation stage
    await doTranslationChunks(lastCombinedText);

  } catch(err){
    log('Pipeline error: ' + (err && err.message || String(err)));
    showOcr('(pipeline error)');
    showTrans('(pipeline error)');
  }
}

/* initial */
log('Ready. Upload an image (Kannada + English). Processing starts automatically.');

</script>
</body>
</html>
